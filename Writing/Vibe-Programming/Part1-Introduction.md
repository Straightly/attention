# Vibe Programming: A Personal Journey
## Part 1: Introduction and Methodology

**Author:** Zhi An  
**Date:** November 10, 2025  

---

## Abstract

"Vibe programming" represents a paradigm shift in software development where developers use natural language to describe intent rather than manually writing code. Coined by Andrej Karpathy in early 2025, the term describes a coding approach where programmers "fully give in to the vibes" and let LLMs generate code based on natural language descriptions. This paper documents a personal 25-day journey of vibe programming using the Windsurf/Cascade AI coding assistant, analyzing 107 recorded prompts across multiple projects. Through this empirical lens, we examine the practical realities, benefits, limitations, and emergent patterns of programming in English‚Äîwhat Karpathy called "the hottest new programming language."

---

## 1. Introduction: The Hottest New Programming Language is English

### 1.1 What is Vibe Programming?

According to Wikipedia and recent academic surveys, **vibe programming** is defined by several key characteristics:

1. **Natural language as primary interface**: Developers describe what they want in English (or other natural languages) rather than writing code
2. **AI-generated code without full understanding**: A key distinction‚Äîif you review and understand every line, you're using AI as a "typing assistant," not vibe coding
3. **Intent articulation over implementation**: Developers shift from being code authors to becoming "intent articulators, context curators, and quality arbiters"
4. **Trust in the vibes**: As Karpathy put it, "forget that the code even exists"

### 1.2 The Three Eras of Software

Andrej Karpathy's framework provides context:

- **Software 1.0**: Computer code (Assembly, C, Java, Python)
- **Software 2.0**: Neural network weights (machine learning models)
- **Software 3.0**: Prompts (natural language instructions to LLMs)

We are witnessing the transition from Software 1.0 to Software 3.0, where the interface between human intent and machine execution fundamentally changes.

### 1.3 Research Context

A 2025 academic survey on vibe coding (arXiv:2510.12399v1) formalizes this as a "dynamic triadic relationship" between:
- **Human developers** (‚Ñã): Intent articulators and quality arbiters
- **Software projects** (ùí´): Multifaceted information spaces
- **Coding Agents** (ùíú): Intelligent executors performing generation, modification, and debugging

This paper examines this triadic relationship through 25 days of real-world practice.

---

## 2. Methodology: A 25-Day Empirical Study

### 2.1 The Setup

**Period**: October 16 - November 8, 2025 (25 days)  
**Tool**: Windsurf IDE with Cascade AI assistant  
**Projects**: Multiple concurrent projects in a single workspace (`/Users/zan/z/attention`)  
**Documentation**: 107 prompts journaled in `journal.md`  
**Approach**: Intentional vibe programming‚Äîusing English as the primary programming language

### 2.2 The Meta-Experiment

The first and most persistent challenge became a meta-experiment itself: **teaching the AI to journal my prompts**. This seemingly simple task revealed fundamental insights about AI behavior, memory, and habit formation‚Äîand became the subject of multiple writings during the study period.

### 2.3 Project Categories

The 107 prompts fell into several categories:

1. **Content Organization** (Prompts 1-5): Organizing 405 Notion backup files
2. **Web Application Development** (Prompts 7-20, 49-51, 68-70, 94-97): Building and iterating on a ToDoApp
3. **Academic Writing** (Prompts 6, 71, 74-77): AI security papers, philosophical essays
4. **Personal Writing** (Prompts 25-34): LinkedIn posts, habit formation articles
5. **Infrastructure & Tools** (Prompts 78-79, 90-93): Git scripts, proxy setup
6. **Meta-Programming** (Prompts 38, 42-47, 57, 65-67, 73): Teaching AI to journal prompts

### 2.4 Prompt Statistics

| Category | Count | Percentage |
|----------|-------|------------|
| Meta-Programming (journaling) | 18 | 16.8% |
| Web Development (ToDoApp) | 14 | 13.1% |
| Academic Writing | 12 | 11.2% |
| Personal Writing | 10 | 9.3% |
| Content Organization | 8 | 7.5% |
| Infrastructure & Tools | 8 | 7.5% |
| Clarifications/Corrections | 12 | 11.2% |
| Other | 25 | 23.4% |
| **Total** | **107** | **100%** |

**Success Rate:**
- Successful on first attempt: ~70 prompts (65%)
- Required clarification: ~15 prompts (14%)
- Required iteration: ~22 prompts (21%)

**Time Investment:**
- Total time: Approximately 20-25 hours
- Output: 1 functional web app, 4 major papers (1,000+ lines), infrastructure improvements
- **ROI**: Estimated 100+ hours of traditional development compressed into 20-25 hours
