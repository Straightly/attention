# Idea

Date: June 13, 2025
Tags: Idea

A conversation with LLM.

Me: “Comparing hosting your own LLM models vs. Use a hosted LLM.”

LLM: A. Control & Customization…; B. Cost Structure...  24/7 chatbot (100k queries/day) $5k/month vs. 30k.  6 times more expensive.  One should expect the later to fall faster. C... Privacy and Compliance.  D. Performance & Latency.  <50ms vs. 100-500ms+ and rate limit at peak usage...  E: Scalability & Maintenance… F: Model Quality & Flexibility…

Me:  “A middle ground is to self hosting on cloud hardware.  Add that to the comparison.

LLM:  … Mistral 7B on 1xT4 GPU (spot) = $110/month vs. GPT-3.5 Turbo $750/month vs. GPT-4 Turbo $15,000/month

Me: Please add Personnel costs. 

LLM:  $625K (on prem) vs. $355 (cloud hosting)  vs. $260K (hosted).

And not to mention TTM.  

My take, however, is based on an observation of the Chinese manufacturing. With this model, after a fairly long time of about 40 years, the Chinese now have the personnels what can produce while the US are struggling to find these people.